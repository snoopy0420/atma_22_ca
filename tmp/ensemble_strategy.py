"""
ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’çµ„ã¿åˆã‚ã›ã¦ã‚¹ã‚³ã‚¢å‘ä¸Š
"""
import os
import sys
import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
from typing import List, Dict, Tuple
from collections import Counter

sys.path.append(os.path.abspath('..'))
from configs.config import *
from src.util import Metric


class EnsembleStrategy:
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, logger=None):
        self.logger = logger
    
    def log(self, msg):
        """ãƒ­ã‚°å‡ºåŠ›"""
        if self.logger:
            self.logger.info(msg)
        else:
            print(msg)
    
    # ========================================================================
    # 1. Votingï¼ˆæŠ•ç¥¨ï¼‰ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
    # ========================================================================
    
    def hard_voting(self, predictions_list: List[np.ndarray]) -> np.ndarray:
        """Hard Votingï¼ˆå¤šæ•°æ±ºï¼‰
        
        å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã§å¤šæ•°æ±ºã‚’å–ã‚‹
        
        Args:
            predictions_list: å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãƒ©ãƒ™ãƒ« [N,] ã®ãƒªã‚¹ãƒˆ
        
        Returns:
            ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ [N,]
        """
        self.log(f"Hard Voting: {len(predictions_list)}ãƒ¢ãƒ‡ãƒ«")
        
        # å„ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«å¤šæ•°æ±º
        ensemble_pred = []
        for i in range(len(predictions_list[0])):
            votes = [pred[i] for pred in predictions_list]
            # æœ€é »å€¤ã‚’æ¡ç”¨
            most_common = Counter(votes).most_common(1)[0][0]
            ensemble_pred.append(most_common)
        
        return np.array(ensemble_pred)
    
    def soft_voting(self, 
                   similarities_list: List[torch.Tensor],
                   threshold: float = 0.5) -> np.ndarray:
        """Soft Votingï¼ˆç¢ºç‡å¹³å‡ï¼‰
        
        å„ãƒ¢ãƒ‡ãƒ«ã®cosé¡ä¼¼åº¦ã‚’å¹³å‡ã—ã¦ã‹ã‚‰äºˆæ¸¬
        
        Args:
            similarities_list: å„ãƒ¢ãƒ‡ãƒ«ã®é¡ä¼¼åº¦è¡Œåˆ— [N, num_classes] ã®ãƒªã‚¹ãƒˆ
            threshold: unknownåˆ¤å®šé–¾å€¤
        
        Returns:
            ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ [N,]
        """
        self.log(f"Soft Voting: {len(similarities_list)}ãƒ¢ãƒ‡ãƒ«")
        
        # é¡ä¼¼åº¦ã‚’å¹³å‡
        avg_similarities = torch.stack(similarities_list).mean(dim=0)  # [N, num_classes]
        
        # æœ€å¤§é¡ä¼¼åº¦ã§äºˆæ¸¬
        max_sims, max_indices = avg_similarities.max(dim=1)
        
        # é–¾å€¤åˆ¤å®š
        predictions = []
        for sim, idx in zip(max_sims.tolist(), max_indices.tolist()):
            predictions.append(-1 if sim < threshold else idx)
        
        return np.array(predictions)
    
    # ========================================================================
    # 2. Weighted Ensembleï¼ˆé‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
    # ========================================================================
    
    def weighted_soft_voting(self,
                            similarities_list: List[torch.Tensor],
                            weights: List[float],
                            threshold: float = 0.5) -> np.ndarray:
        """Weighted Soft Voting
        
        å„ãƒ¢ãƒ‡ãƒ«ã®é¡ä¼¼åº¦ã‚’é‡ã¿ä»˜ãå¹³å‡
        
        Args:
            similarities_list: å„ãƒ¢ãƒ‡ãƒ«ã®é¡ä¼¼åº¦è¡Œåˆ—
            weights: å„ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ï¼ˆOOFã‚¹ã‚³ã‚¢ãªã©ã‹ã‚‰ç®—å‡ºï¼‰
            threshold: unknownåˆ¤å®šé–¾å€¤
        
        Returns:
            ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        """
        self.log(f"Weighted Soft Voting: {len(similarities_list)}ãƒ¢ãƒ‡ãƒ«")
        self.log(f"  é‡ã¿: {weights}")
        
        # é‡ã¿ã‚’æ­£è¦åŒ–
        weights = np.array(weights) / np.sum(weights)
        
        # é‡ã¿ä»˜ãå¹³å‡
        weighted_avg = sum(w * sim for w, sim in zip(weights, similarities_list))
        
        # äºˆæ¸¬
        max_sims, max_indices = weighted_avg.max(dim=1)
        predictions = []
        for sim, idx in zip(max_sims.tolist(), max_indices.tolist()):
            predictions.append(-1 if sim < threshold else idx)
        
        return np.array(predictions)
    
    # ========================================================================
    # 3. Rank Averagingï¼ˆé †ä½å¹³å‡ï¼‰
    # ========================================================================
    
    def rank_averaging(self,
                      similarities_list: List[torch.Tensor],
                      threshold: float = 0.5) -> np.ndarray:
        """Rank Averaging
        
        å„ãƒ¢ãƒ‡ãƒ«ã®é¡ä¼¼åº¦ã‚’é †ä½ã«å¤‰æ›ã—ã¦ã‹ã‚‰å¹³å‡
        ã‚¹ã‚±ãƒ¼ãƒ«ã®é•ã„ã«é ‘å¥
        
        Args:
            similarities_list: å„ãƒ¢ãƒ‡ãƒ«ã®é¡ä¼¼åº¦è¡Œåˆ—
            threshold: unknownåˆ¤å®šé–¾å€¤
        
        Returns:
            ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        """
        self.log(f"Rank Averaging: {len(similarities_list)}ãƒ¢ãƒ‡ãƒ«")
        
        # å„ãƒ¢ãƒ‡ãƒ«ã§é †ä½ã«å¤‰æ›ï¼ˆå„ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ï¼‰
        rank_list = []
        for sims in similarities_list:
            # argsortã§é †ä½ã‚’å–å¾—ï¼ˆé™é †ï¼‰
            ranks = sims.argsort(dim=1, descending=True).argsort(dim=1).float()
            rank_list.append(ranks)
        
        # é †ä½ã‚’å¹³å‡
        avg_ranks = torch.stack(rank_list).mean(dim=0)
        
        # é †ä½ãŒæœ€å°ï¼ˆæœ€ã‚‚è‰¯ã„ï¼‰ã®ã‚¯ãƒ©ã‚¹ã‚’é¸æŠ
        best_classes = avg_ranks.argmin(dim=1)
        
        # å…ƒã®é¡ä¼¼åº¦ã®å¹³å‡ã§unknownåˆ¤å®š
        avg_similarities = torch.stack(similarities_list).mean(dim=0)
        max_sims = avg_similarities.gather(1, best_classes.unsqueeze(1)).squeeze()
        
        # äºˆæ¸¬
        predictions = []
        for sim, idx in zip(max_sims.tolist(), best_classes.tolist()):
            predictions.append(-1 if sim < threshold else idx)
        
        return np.array(predictions)
    
    # ========================================================================
    # 4. Stackingï¼ˆã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ï¼‰
    # ========================================================================
    
    def simple_stacking(self,
                       train_predictions: List[np.ndarray],
                       test_predictions: List[np.ndarray],
                       train_labels: np.ndarray) -> np.ndarray:
        """Simple Stacking
        
        OOFäºˆæ¸¬ã‚’ç‰¹å¾´é‡ã¨ã—ã¦2æ®µç›®ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
        ï¼ˆç°¡æ˜“ç‰ˆ: æŠ•ç¥¨ãƒ™ãƒ¼ã‚¹ã®æ±ºå®šæœ¨ï¼‰
        
        Args:
            train_predictions: OOFäºˆæ¸¬ã®ãƒªã‚¹ãƒˆ [N,] x M
            test_predictions: ãƒ†ã‚¹ãƒˆäºˆæ¸¬ã®ãƒªã‚¹ãƒˆ [N,] x M
            train_labels: è¨“ç·´ãƒ©ãƒ™ãƒ« [N,]
        
        Returns:
            ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        """
        from sklearn.ensemble import RandomForestClassifier
        
        self.log(f"Simple Stacking: {len(train_predictions)}ãƒ¢ãƒ‡ãƒ«")
        
        # OOFäºˆæ¸¬ã‚’ç‰¹å¾´é‡ã«å¤‰æ›
        X_train = np.column_stack(train_predictions)  # [N, M]
        X_test = np.column_stack(test_predictions)    # [N_test, M]
        
        # 2æ®µç›®ãƒ¢ãƒ‡ãƒ«ï¼ˆRandom Forestï¼‰
        meta_model = RandomForestClassifier(
            n_estimators=100,
            max_depth=5,
            random_state=42
        )
        meta_model.fit(X_train, train_labels)
        
        # äºˆæ¸¬
        ensemble_pred = meta_model.predict(X_test)
        
        return ensemble_pred
    
    # ========================================================================
    # 5. Confidence-based Ensembleï¼ˆä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
    # ========================================================================
    
    def confidence_based_ensemble(self,
                                 similarities_list: List[torch.Tensor],
                                 threshold: float = 0.5) -> np.ndarray:
        """Confidence-based Ensemble
        
        å„ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«æœ€ã‚‚ä¿¡é ¼åº¦ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’æ¡ç”¨
        
        Args:
            similarities_list: å„ãƒ¢ãƒ‡ãƒ«ã®é¡ä¼¼åº¦è¡Œåˆ—
            threshold: unknownåˆ¤å®šé–¾å€¤
        
        Returns:
            ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        """
        self.log(f"Confidence-based Ensemble: {len(similarities_list)}ãƒ¢ãƒ‡ãƒ«")
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®æœ€å¤§é¡ä¼¼åº¦ã‚’å–å¾—
        max_sims_list = [sims.max(dim=1)[0] for sims in similarities_list]  # [N,] x M
        max_indices_list = [sims.max(dim=1)[1] for sims in similarities_list]
        
        # ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«æœ€ã‚‚ä¿¡é ¼åº¦ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        all_max_sims = torch.stack(max_sims_list, dim=1)  # [N, M]
        best_model_indices = all_max_sims.argmax(dim=1)  # [N,]
        
        # é¸ã°ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’æ¡ç”¨
        predictions = []
        for i, model_idx in enumerate(best_model_indices.tolist()):
            sim = max_sims_list[model_idx][i].item()
            idx = max_indices_list[model_idx][i].item()
            predictions.append(-1 if sim < threshold else idx)
        
        return np.array(predictions)
    
    # ========================================================================
    # 6. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡
    # ========================================================================
    
    def evaluate_ensemble_strategies(self,
                                    similarities_list: List[torch.Tensor],
                                    predictions_list: List[np.ndarray],
                                    true_labels: np.ndarray,
                                    threshold: float = 0.5) -> pd.DataFrame:
        """å„ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ã‚’è©•ä¾¡
        
        Args:
            similarities_list: å„ãƒ¢ãƒ‡ãƒ«ã®é¡ä¼¼åº¦è¡Œåˆ—
            predictions_list: å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãƒ©ãƒ™ãƒ«
            true_labels: æ­£è§£ãƒ©ãƒ™ãƒ«
            threshold: unknownåˆ¤å®šé–¾å€¤
        
        Returns:
            è©•ä¾¡çµæœã®DataFrame
        """
        self.log("\n" + "="*80)
        self.log("ğŸ“Š ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ã®æ¯”è¼ƒ")
        self.log("="*80)
        
        results = []
        
        # 1. Hard Voting
        pred = self.hard_voting(predictions_list)
        score = Metric.macro_f1(true_labels, pred)
        results.append({'strategy': 'Hard Voting', 'macro_f1': score})
        self.log(f"Hard Voting: {score:.5f}")
        
        # 2. Soft Voting
        pred = self.soft_voting(similarities_list, threshold)
        score = Metric.macro_f1(true_labels, pred)
        results.append({'strategy': 'Soft Voting', 'macro_f1': score})
        self.log(f"Soft Voting: {score:.5f}")
        
        # 3. Rank Averaging
        pred = self.rank_averaging(similarities_list, threshold)
        score = Metric.macro_f1(true_labels, pred)
        results.append({'strategy': 'Rank Averaging', 'macro_f1': score})
        self.log(f"Rank Averaging: {score:.5f}")
        
        # 4. Confidence-based
        pred = self.confidence_based_ensemble(similarities_list, threshold)
        score = Metric.macro_f1(true_labels, pred)
        results.append({'strategy': 'Confidence-based', 'macro_f1': score})
        self.log(f"Confidence-based: {score:.5f}")
        
        # å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚‚è¡¨ç¤º
        self.log("\nã€å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã€‘")
        for i, pred in enumerate(predictions_list):
            score = Metric.macro_f1(true_labels, pred)
            results.append({'strategy': f'Model {i}', 'macro_f1': score})
            self.log(f"Model {i}: {score:.5f}")
        
        df_results = pd.DataFrame(results).sort_values('macro_f1', ascending=False)
        
        self.log("\n" + "="*80)
        self.log("æœ€è‰¯æˆ¦ç•¥: " + df_results.iloc[0]['strategy'])
        self.log(f"ã‚¹ã‚³ã‚¢: {df_results.iloc[0]['macro_f1']:.5f}")
        self.log("="*80)
        
        return df_results


# ============================================================================
# å®Ÿè£…ã‚¬ã‚¤ãƒ‰
# ============================================================================

"""
ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ã®é¸ã³æ–¹ã€‘

1. Hard Voting
   - æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«
   - ãƒ¢ãƒ‡ãƒ«æ•°ãŒå°‘ãªã„ï¼ˆ2-3å€‹ï¼‰æ™‚ã«åŠ¹æœçš„
   - äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã®ã¿ã§å®Ÿè£…å¯èƒ½

2. Soft Voting
   - æœ€ã‚‚ä¸€èˆ¬çš„ã§åŠ¹æœçš„
   - ãƒ¢ãƒ‡ãƒ«æ•°ãŒå¤šã„ï¼ˆ3-5å€‹ï¼‰æ™‚ã«æœ‰åŠ¹
   - é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ãŒå¿…è¦

3. Weighted Soft Voting
   - å„ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å·®ãŒå¤§ãã„æ™‚ã«æœ‰åŠ¹
   - OOFã‚¹ã‚³ã‚¢ã§é‡ã¿ã‚’è¨­å®š
   - é‡ã¿æœ€é©åŒ–ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹

4. Rank Averaging
   - ãƒ¢ãƒ‡ãƒ«é–“ã§ã‚¹ã‚±ãƒ¼ãƒ«ãŒå¤§ããç•°ãªã‚‹æ™‚ã«æœ‰åŠ¹
   - é ‘å¥æ€§ãŒé«˜ã„

5. Confidence-based
   - å„ãƒ¢ãƒ‡ãƒ«ãŒå¾—æ„ãªã‚µãƒ³ãƒ—ãƒ«ãŒç•°ãªã‚‹æ™‚ã«æœ‰åŠ¹
   - æ¨è«–æ™‚é–“ã¯å¤‰ã‚ã‚‰ãªã„

6. Stacking
   - æœ€ã‚‚é«˜æ€§èƒ½ã ãŒå®Ÿè£…ã‚³ã‚¹ãƒˆãŒé«˜ã„
   - OOFäºˆæ¸¬ãŒå¿…è¦
   - éå­¦ç¿’ã«æ³¨æ„

ã€æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‘
â‘  ã¾ãšSoft Votingã§è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹
â‘¡ ã‚¹ã‚³ã‚¢å·®ãŒå¤§ãã„å ´åˆã¯Weighted Soft Votingã‚’è©¦ã™
â‘¢ ã•ã‚‰ã«æ”¹å–„ã—ãŸã„å ´åˆã¯Rank Averagingã‚„Stacking

ã€ãƒ¢ãƒ‡ãƒ«ã®å¤šæ§˜æ€§ç¢ºä¿ã€‘
- ç•°ãªã‚‹ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ï¼ˆEfficientNet, ResNet, ViTï¼‰
- ç•°ãªã‚‹ç”»åƒã‚µã‚¤ã‚ºï¼ˆ224, 384, 512ï¼‰
- ç•°ãªã‚‹augmentationè¨­å®š
- ç•°ãªã‚‹lossé–¢æ•°ï¼ˆArcFace, CosFace, Tripletï¼‰
"""

if __name__ == "__main__":
    # ä½¿ç”¨ä¾‹
    from src.util import Logger
    
    logger = Logger()
    ensemble = EnsembleStrategy(logger)
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèª
    n_samples = 1000
    n_models = 3
    n_classes = 11
    
    # ãƒ€ãƒŸãƒ¼é¡ä¼¼åº¦è¡Œåˆ—
    similarities_list = [
        torch.randn(n_samples, n_classes).softmax(dim=1) 
        for _ in range(n_models)
    ]
    
    # ãƒ€ãƒŸãƒ¼äºˆæ¸¬
    predictions_list = [
        sims.argmax(dim=1).numpy() 
        for sims in similarities_list
    ]
    
    # ãƒ€ãƒŸãƒ¼æ­£è§£ãƒ©ãƒ™ãƒ«
    true_labels = np.random.randint(0, n_classes, n_samples)
    
    # è©•ä¾¡
    results = ensemble.evaluate_ensemble_strategies(
        similarities_list,
        predictions_list,
        true_labels,
        threshold=0.5
    )
    
    print("\n" + "="*80)
    print(results)
