"""
é–¾å€¤ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
cosé¡ä¼¼åº¦ã®é–¾å€¤ã‚’æœ€é©åŒ–ã—ã¦Macro F1ã‚’æœ€å¤§åŒ–
"""
import os
import sys
import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
from tqdm import tqdm
from typing import Tuple, List
import matplotlib.pyplot as plt

sys.path.append(os.path.abspath('..'))
from configs.config import *
from src.util import Metric


class ThresholdOptimizer:
    """é–¾å€¤æœ€é©åŒ–ã‚¯ãƒ©ã‚¹
    
    åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã¨ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‹ã‚‰æœ€é©ãªé–¾å€¤ã‚’æ¢ç´¢
    """
    
    def __init__(self, logger=None):
        self.logger = logger
    
    def log(self, msg):
        """ãƒ­ã‚°å‡ºåŠ›"""
        if self.logger:
            self.logger.info(msg)
        else:
            print(msg)
    
    def optimize_threshold(self,
                          embeddings: torch.Tensor,
                          prototypes: torch.Tensor,
                          true_labels: np.ndarray,
                          threshold_range: Tuple[float, float] = (0.0, 1.0),
                          n_steps: int = 100) -> Tuple[float, float]:
        """æœ€é©é–¾å€¤ã‚’æ¢ç´¢
        
        Args:
            embeddings: åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ« [N, embedding_dim]
            prototypes: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ™ã‚¯ãƒˆãƒ« [num_classes, embedding_dim]
            true_labels: æ­£è§£ãƒ©ãƒ™ãƒ« [N]
            threshold_range: æ¢ç´¢ç¯„å›² (min, max)
            n_steps: æ¢ç´¢ã‚¹ãƒ†ãƒƒãƒ—æ•°
        
        Returns:
            best_threshold: æœ€é©é–¾å€¤
            best_score: æœ€é«˜ã‚¹ã‚³ã‚¢ï¼ˆMacro F1ï¼‰
        """
        self.log("\n" + "="*80)
        self.log("ğŸ¯ é–¾å€¤æœ€é©åŒ–ã‚’é–‹å§‹")
        self.log("="*80)
        
        # cosé¡ä¼¼åº¦ã‚’è¨ˆç®—
        similarities = F.linear(embeddings, prototypes)  # [N, num_classes]
        max_sims, max_indices = similarities.max(dim=1)  # [N]
        
        # é–¾å€¤å€™è£œ
        thresholds = np.linspace(threshold_range[0], threshold_range[1], n_steps)
        scores = []
        
        self.log(f"æ¢ç´¢ç¯„å›²: {threshold_range[0]:.3f} ~ {threshold_range[1]:.3f}")
        self.log(f"ã‚¹ãƒ†ãƒƒãƒ—æ•°: {n_steps}")
        
        # å„é–¾å€¤ã§ã‚¹ã‚³ã‚¢è¨ˆç®—
        for threshold in tqdm(thresholds, desc="é–¾å€¤æ¢ç´¢"):
            # é–¾å€¤ã§äºˆæ¸¬ã‚’æ±ºå®š
            predictions = []
            for sim, idx in zip(max_sims.tolist(), max_indices.tolist()):
                predictions.append(-1 if sim < threshold else idx)
            
            # Macro F1ã‚’è¨ˆç®—
            score = Metric.macro_f1(true_labels, np.array(predictions))
            scores.append(score)
        
        # æœ€é©é–¾å€¤ã‚’ç‰¹å®š
        best_idx = np.argmax(scores)
        best_threshold = thresholds[best_idx]
        best_score = scores[best_idx]
        
        self.log(f"\næœ€é©é–¾å€¤: {best_threshold:.4f}")
        self.log(f"Macro F1: {best_score:.5f}")
        
        # unknownäºˆæ¸¬ã®å‰²åˆã‚’è¡¨ç¤º
        test_sims = max_sims.numpy()
        unknown_ratio = (test_sims < best_threshold).mean()
        self.log(f"unknownäºˆæ¸¬å‰²åˆ: {unknown_ratio*100:.2f}%")
        
        return best_threshold, best_score
    
    def plot_threshold_curve(self,
                            embeddings: torch.Tensor,
                            prototypes: torch.Tensor,
                            true_labels: np.ndarray,
                            output_path: str,
                            threshold_range: Tuple[float, float] = (0.0, 1.0),
                            n_steps: int = 100):
        """é–¾å€¤ã¨ã‚¹ã‚³ã‚¢ã®é–¢ä¿‚ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        
        Args:
            embeddings: åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
            prototypes: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ™ã‚¯ãƒˆãƒ«
            true_labels: æ­£è§£ãƒ©ãƒ™ãƒ«
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            threshold_range: æ¢ç´¢ç¯„å›²
            n_steps: ã‚¹ãƒ†ãƒƒãƒ—æ•°
        """
        # cosé¡ä¼¼åº¦ã‚’è¨ˆç®—
        similarities = F.linear(embeddings, prototypes)
        max_sims, max_indices = similarities.max(dim=1)
        
        # é–¾å€¤ã”ã¨ã®ã‚¹ã‚³ã‚¢
        thresholds = np.linspace(threshold_range[0], threshold_range[1], n_steps)
        scores = []
        unknown_ratios = []
        
        for threshold in thresholds:
            predictions = []
            for sim, idx in zip(max_sims.tolist(), max_indices.tolist()):
                predictions.append(-1 if sim < threshold else idx)
            
            score = Metric.macro_f1(true_labels, np.array(predictions))
            scores.append(score)
            
            unknown_ratio = (max_sims.numpy() < threshold).mean()
            unknown_ratios.append(unknown_ratio * 100)
        
        # ãƒ—ãƒ­ãƒƒãƒˆ
        fig, ax1 = plt.subplots(figsize=(12, 6))
        
        # Macro F1
        color = 'tab:blue'
        ax1.set_xlabel('Threshold', fontsize=12)
        ax1.set_ylabel('Macro F1', color=color, fontsize=12)
        ax1.plot(thresholds, scores, color=color, linewidth=2, label='Macro F1')
        ax1.tick_params(axis='y', labelcolor=color)
        ax1.grid(True, alpha=0.3)
        
        # æœ€é©ç‚¹ã‚’ãƒãƒ¼ã‚¯
        best_idx = np.argmax(scores)
        ax1.scatter([thresholds[best_idx]], [scores[best_idx]], 
                   color='red', s=100, zorder=5, label=f'Best: {thresholds[best_idx]:.3f}')
        
        # unknownå‰²åˆ
        ax2 = ax1.twinx()
        color = 'tab:orange'
        ax2.set_ylabel('Unknown Ratio (%)', color=color, fontsize=12)
        ax2.plot(thresholds, unknown_ratios, color=color, linewidth=2, 
                linestyle='--', label='Unknown Ratio')
        ax2.tick_params(axis='y', labelcolor=color)
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã¨å‡¡ä¾‹
        plt.title('Threshold vs Macro F1 / Unknown Ratio', fontsize=14, fontweight='bold')
        
        # å‡¡ä¾‹ã‚’çµ±åˆ
        lines1, labels1 = ax1.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        ax1.legend(lines1 + lines2, labels1 + labels2, loc='best', fontsize=10)
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        self.log(f"é–¾å€¤ã‚«ãƒ¼ãƒ–ä¿å­˜: {output_path}")
    
    def analyze_similarity_distribution(self,
                                       embeddings: torch.Tensor,
                                       prototypes: torch.Tensor,
                                       true_labels: np.ndarray,
                                       output_path: str):
        """é¡ä¼¼åº¦åˆ†å¸ƒã®å¯è¦–åŒ–
        
        Args:
            embeddings: åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
            prototypes: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ™ã‚¯ãƒˆãƒ«
            true_labels: æ­£è§£ãƒ©ãƒ™ãƒ«
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # cosé¡ä¼¼åº¦ã‚’è¨ˆç®—
        similarities = F.linear(embeddings, prototypes)
        max_sims, max_indices = similarities.max(dim=1)
        
        # æ­£è§£/ä¸æ­£è§£ã§åˆ†é¡
        correct_mask = (max_indices.numpy() == true_labels)
        correct_sims = max_sims[correct_mask].numpy()
        incorrect_sims = max_sims[~correct_mask].numpy()
        
        # ãƒ—ãƒ­ãƒƒãƒˆ
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        axes[0].hist(correct_sims, bins=50, alpha=0.6, label='Correct', color='green', edgecolor='black')
        axes[0].hist(incorrect_sims, bins=50, alpha=0.6, label='Incorrect', color='red', edgecolor='black')
        axes[0].set_xlabel('Max Cosine Similarity', fontsize=12)
        axes[0].set_ylabel('Count', fontsize=12)
        axes[0].set_title('Similarity Distribution', fontsize=14)
        axes[0].legend(fontsize=10)
        axes[0].grid(True, alpha=0.3)
        
        # ç´¯ç©åˆ†å¸ƒ
        axes[1].hist(correct_sims, bins=50, alpha=0.6, label='Correct', 
                    color='green', cumulative=True, density=True, histtype='step', linewidth=2)
        axes[1].hist(incorrect_sims, bins=50, alpha=0.6, label='Incorrect', 
                    color='red', cumulative=True, density=True, histtype='step', linewidth=2)
        axes[1].set_xlabel('Max Cosine Similarity', fontsize=12)
        axes[1].set_ylabel('Cumulative Probability', fontsize=12)
        axes[1].set_title('Cumulative Distribution', fontsize=14)
        axes[1].legend(fontsize=10)
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        self.log(f"é¡ä¼¼åº¦åˆ†å¸ƒä¿å­˜: {output_path}")
        
        # çµ±è¨ˆæƒ…å ±
        self.log("\nã€é¡ä¼¼åº¦çµ±è¨ˆã€‘")
        self.log(f"æ­£è§£æ™‚: å¹³å‡={correct_sims.mean():.4f}, ä¸­å¤®å€¤={np.median(correct_sims):.4f}, æ¨™æº–åå·®={correct_sims.std():.4f}")
        self.log(f"ä¸æ­£è§£æ™‚: å¹³å‡={incorrect_sims.mean():.4f}, ä¸­å¤®å€¤={np.median(incorrect_sims):.4f}, æ¨™æº–åå·®={incorrect_sims.std():.4f}")


def optimize_threshold_from_oof(model_dir: str, 
                                train_df: pd.DataFrame,
                                logger=None) -> float:
    """OOFäºˆæ¸¬ã‹ã‚‰æœ€é©é–¾å€¤ã‚’æ¢ç´¢
    
    Args:
        model_dir: ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        train_df: è¨“ç·´ãƒ‡ãƒ¼ã‚¿
        logger: ãƒ­ã‚¬ãƒ¼
    
    Returns:
        æœ€é©é–¾å€¤
    """
    from src.util import Util
    
    optimizer = ThresholdOptimizer(logger)
    
    # OOFäºˆæ¸¬ã¨ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’èª­ã¿è¾¼ã¿ï¼ˆfold0ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ä½¿ç”¨ï¼‰
    # å®Ÿéš›ã«ã¯å…¨foldã®embeddingã‚’ä½¿ã†ã¹ãã ãŒã€ç°¡æ˜“ç‰ˆã¨ã—ã¦fold0ã‚’ä½¿ç”¨
    oof_path = os.path.join(model_dir, 'va_pred.pkl')
    prototype_path = os.path.join(model_dir, f'{os.path.basename(model_dir)}_fold-0', 'prototypes.pth')
    
    if not os.path.exists(prototype_path):
        optimizer.log(f"ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prototype_path}")
        return 0.5
    
    # ã“ã“ã§ã¯ç°¡æ˜“å®Ÿè£…ã¨ã—ã¦ã€åŸ‹ã‚è¾¼ã¿ã‚’å†è¨ˆç®—ã›ãšãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
    # å®Ÿéš›ã«ã¯å„foldã§åŸ‹ã‚è¾¼ã¿ã‚’æŠ½å‡ºã—ã¦æœ€é©åŒ–ã™ã¹ã
    optimizer.log("é–¾å€¤æœ€é©åŒ–ã¯Notebookã§å®Ÿè¡Œã—ã¦ãã ã•ã„")
    
    return 0.5


if __name__ == "__main__":
    # ä½¿ç”¨ä¾‹
    from src.util import Logger
    
    logger = Logger()
    logger.info("é–¾å€¤æœ€é©åŒ–ãƒ„ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ")
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèª
    embeddings = torch.randn(1000, 512)
    embeddings = F.normalize(embeddings, p=2, dim=1)
    
    prototypes = torch.randn(11, 512)
    prototypes = F.normalize(prototypes, p=2, dim=1)
    
    true_labels = np.random.randint(0, 11, 1000)
    
    optimizer = ThresholdOptimizer(logger)
    best_threshold, best_score = optimizer.optimize_threshold(
        embeddings, prototypes, true_labels,
        threshold_range=(0.3, 0.8),
        n_steps=50
    )
    
    # ãƒ—ãƒ­ãƒƒãƒˆ
    optimizer.plot_threshold_curve(
        embeddings, prototypes, true_labels,
        output_path='/workspace/atma_22_ca/data/figures/threshold_curve_test.png',
        threshold_range=(0.3, 0.8),
        n_steps=50
    )
    
    optimizer.analyze_similarity_distribution(
        embeddings, prototypes, true_labels,
        output_path='/workspace/atma_22_ca/data/figures/similarity_dist_test.png'
    )
