# リポジトリ/プロジェクトの概要
このリポジトリは、atmaCup#22という機械学習コンペティションのためのコードです。

詳細な説明は以下の概要部分を参照してください。

# 開発ガイドライン
このリポジトリでコードを追加・修正する際の基本指針です。

## 基本方針
1. 変更はタスク目的に最小限に留める（無関係なリファクタは避ける）。
2. 再利用可能な処理は `src/` 配下で機能別モジュールへ分離（例: `src/model_lgbm.py` など）。
3. **実験・実行・可視化は Notebook で実施**。`notebooks/` 配下で実験用ノートブックを作成し、パラメータ調整や結果確認を行う。
4. Notebook 内で有効性が確認されたロジックは、再利用性を考慮して `src/` 配下のモジュールへ移植する。
5. **新しいライブラリを使用する場合は `requirements.txt` に追記する**（バージョン指定推奨）。
6. 外部APIキーや秘密情報はハードコードしない（`.env` を導入する場合はテンプレ例のみ）。
7. **ログ出力や標準出力は基本的に日本語で記載する**（`logger.info()` のメッセージは日本語を使用）。実験結果の追跡性を高めるため。

## 画像コンペ特有の設計方針（atmaCup#22）
本コンペは**画像コンペ**であるため、以下の構成を採用する：

### Model-Runner-Notebookパターン
過去のテーブルコンペで使用した構成を踏襲し、画像タスクに最適化:
- **Model抽象クラス**: `src/model.py` で `train()`, `predict()`, `save_model()`, `load_model()` を定義
- **具体的なモデル**: `src/model_resnet.py`, `src/model_arcface.py` などでModel継承
- **Runnerクラス**: `src/runner.py` でCV管理・学習・予測・評価を一元管理
- **Notebookで実行**: `notebooks/exp_*.ipynb` でパラメータ設定→Runner実行→分析

詳細なコードはsample_code/自分の過去コンペ/配下を参照。

### 画像コンペ必須の技術要素
1. **PyTorch Dataset/DataLoader**: 
   - `src/dataset_image.py` でバッチごとのデータ読み込み
   - メモリ効率化と並列化（`num_workers`）
   - Data Augmentation管理（`get_transforms()`）

2. **FeatureCache**:
   - `src/feature_cache.py` で特徴量の自動キャッシュ
│   └── exp_resnet.ipynb          # ResNet50ベースライン実験
├── sample_code/                  # 参考サンプル（他人のコードなど）
├── src/                          # 再利用可能なロジックを記載したPython モジュール群
│   ├── model.py                  # Model抽象クラス
│   ├── model_resnet.py           # ResNet50ベースの画像特徴抽出モデル
│   ├── runner.py                 # CV管理・学習・予測・評価
│   ├── util.py                   # Logger, Util, Metric
│   ├── dataset_image.py          # PyTorch Dataset/DataLoader/Transforms
│   └── feature_cache.py          # 特徴量キャッシュ管理
├── docs/                         # ドキュメント
│   ├── image_competition_best_practices.md  # 画像コンペのベストプラクティス
│   └── improvements_summary.md   # 改良まとめ
└── .github/
	└── copilot-instructions.md   # このリポジトリの開発/運用ガイド
  └── data_discription.md      # データセットの詳細説明
```

追加・変更時の原則:
- **実験・実行は `notebooks/` で実施**: パラメータ調整、結果確認、可視化はノートブックで行う。
- **Model-Runner-Notebookパターン**: 過去コンペの構成を踏襲し、画像タスクに最適化。
- **画像コンペ必須要素**: Dataset/DataLoader（`dataset_image.py`）、FeatureCache（`feature_cache.py`）を必ず使用。
- `src/` に置くコードは「再利用可能な機能」を意識したクラス化・関数化を行う（データ読み込み、特徴抽出、予測ロジックなど）。
- Notebook 内で有効性が確認されたロジックは、再現性確保のため必要に応じて `src/` へ移植。
- **特徴抽出は時間がかかるため、必ずFeatureCacheを使用**して2回目以降の高速化を図る。
- 大きい変更を実施する場合は、変更計画を事前に確認する。

## 実装の流れ（画像コンペ）
1. **Notebookでパラメータ設定**: `notebooks/exp_*.ipynb` でモデル・CV設定
2. **Runner作成**: モデルクラス・データ・パラメータを渡してRunnerインスタンス化
3. **CV学習**: `runner.train_cv()` で5-fold学習（初回は特徴抽出で時間がかかる）
4. **予測**: `runner.predict_cv()` でアンサンブル予測
5. **閾値チューニング**: `model.predict_with_custom_threshold()` で高速実験
6. **提出**: `runner.save_submission()` でCSV生成
# フォルダ構成
主要ディレクトリの役割と追加時の注意点。

```
.
├── README.md                     # リポジトリ全体の簡易概要
├── requirements.txt              # 依存パッケージ
├── configs/
│   └── config.py                 # 設定値（定数/パス）を集中管理
├── data/
│   ├── raw/                      # 生データ（配布物・外部取得データ）
│   │   └── input/                # コンペ配布の入力ファイル類
│   ├── interim/                  # 中間生成物（フィルタ後/正規化後など）
│   ├── features/                 # 特徴量生成結果（数値・埋め込み等）
│   ├── figures/                  # 可視化出力（PNG/HTML等）
│   └── submission/               # 提出用CSVの生成先
├── logs/                         # 実行ログ（日時付きファイル推奨）
├── models/                       # モデル/チェックポイント（必要時のみ）
├── notebooks/                    # 実験/実行用 Notebook（パラメータ調整・可視化・実行）
├── sample_code/                  # 参考サンプル（他人のコードなど）
├── src/                          # 再利用可能なロジックを記載したPython モジュール群
└── .github/
	└── copilot-instructions.md   # このリポジトリの開発/運用ガイド
  └── data_discription.md      # データセットの詳細説明
```

追加・変更時の原則:
- **実験・実行は `notebooks/` で実施**: パラメータ調整、結果確認、可視化はノートブックで行う。
- `src/` に置くコードは「再利用可能な機能」を意識したクラス化・関数化を行う（データ読み込み、特徴抽出、予測ロジックなど）。
- Notebook 内で有効性が確認されたロジックは、再現性確保のため必要に応じて `src/` へ移植。
- 大きい変更を実施する場合は、変更計画を事前に確認する。



# コンペの概要説明

バスケットボール選手判別チャレンジ
このコンペティションのゴールは、バスケットボールの試合動画から切り出された静止画に対し、「特定のバウンディングボックス（bbox）に写っている選手が誰であるか」 を正確に識別することです。

具体的には、画像と 選手の位置（bbox）が与えられるので、その位置にいる選手のID（ラベル） を予測していただきます。

もともとは動画のデータですがみなさんにお渡しするのは動画を静止画として切り出した画像リストです。
各画像にたいして「どこに」「誰が」写っているかの領域(bounding box) x ラベルの情報がメタ情報として渡されます。学習データでは全てのフレームに対してどこに誰がいるかのすべての情報が渡されます。
対してテストデータでは各画像にたいして「どこに」写っているかの bbox 情報のみが渡されますので「誰が」写っているかのラベルを予測してください!
学習データでは同じシーンを上 (フカン) と横から取った画像が渡されます。予測時には一部のフレームでは両方の画像があり、残りは横からの画像しか与えられません。
試合途中には、選手の入れ替えが発生しています (どのタイミングで入れ替えがあるか?については知らされません)。もしもテストデータで、学習データに存在していない選手が登場した場合には unknown に該当するラベル -1 を出力してください。

# 評価指標
Macro F1 で評価を行います。

## データセット
<!-- データセットの詳細については、`.github/data_discription.md` を参照してください。 -->

## 画像データ

試合動画のフレームごとの画像が格納されています。ファイル名は { クオーター番号 }__{ 画角 }__{ シーンセッション番号 }__{ フレーム番号 }.jpg のルールで命名されています。

- クオーター番号: 試合のクオーターを表す番号。試合の経過に従って番号が増えます。
- 画角: side or top のいずれかの文字列。side の場合横からの, top の場合フカンカメラの画像であることを表します。
- シーンセッション番号: クオーター中のシーンを表す番号。0 から始まり、時間経過に伴って番号が増えます。シーンの前後には一定の時間があいています。
- フレーム番号: 各シーン内での動画フレーム番号: 0 から始まり、時間経過に伴って番号が増えます。各フレーム間の時刻は一定です。


## メタデータ

### train_meta.csv
各画像のどこに・だれが写っているかを記録しているメタデータです。

- quarter: クオーター番号
- angle: 画角。top or side.
- session: クオーター中のシーンを表すセッション番号。学習データはクオーター中の全画像が含まれているため、セッションは常に 0 です。
- frame: フレーム番号
- x / y / w / h: bbox の位置。pixel として解釈してください。
- label_id: この bbox に写っている選手のID

### test_meta.csv
予測対象となる画像と場所が格納されている CSV です。記載の画像の特定の場所にどの選手がいるかを予測してください。

label_id が存在しないこと / セッションが0以外の値を取りうること / angle が常に side であること以外は train_meta.csv と同じです。

### sample_submission.csv
今回のコンペティションで有効となる sample submission です。label_id 列のみを持つ csv (1列のみなのでカンマでの区切りなし) で test_meta.csv と同じ順序になるようにしてください。

- label_id: test_meta.csv の同一行の bbox に写っている選手のID。もし train_meta.csv にいない選手が写っている場合には -1 を入力してください。

### test_top_meta.csv
テストデータの上から撮影した画像のメタデータ。ただし、全データに対してはあるわけではなく、一部のセッションのみです。test_meta.csv の補助データとしてお使いください。