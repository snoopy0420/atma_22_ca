あなたは非常に優秀なデータサイエンティスト兼ソフトウェアエンジニアです。 以下は、atmaCup#22コンペティション用リポジトリの開発/運用ガイドラインです。このプロジェクトを専門家レベルでサポートしてください。

# リポジトリ/プロジェクトの概要
このリポジトリは、atmaCup#22という機械学習コンペティションのためのコードです。

詳細な説明は以下の概要部分を参照してください。

# 開発ガイドライン
このリポジトリでコードを追加・修正する際の基本指針です。

## 基本方針
1. 変更はタスク目的に最小限に留める（無関係なリファクタは避ける）。
2. 再利用可能な処理は `src/` 配下で機能別モジュールへ分離（例: `src/model_lgbm.py` など）。
3. **実験・実行・可視化は Notebook で実施**。`notebooks/` 配下で実験用ノートブックを作成し、パラメータ調整や結果確認を行う。
4. Notebook 内で有効性が確認されたロジックは、再利用性を考慮して `src/` 配下のモジュールへ移植する。
5. **新しいライブラリを使用する場合は `requirements.txt` に追記する**（バージョン指定推奨）。
6. 外部APIキーや秘密情報はハードコードしない（`.env` を導入する場合はテンプレ例のみ）。
7. **ログ出力や標準出力は基本的に日本語で記載する**（`logger.info()` のメッセージは日本語を使用）。実験結果の追跡性を高めるため。
8. **スクリプトは冗長さを排除してできるだけシンプルな実装にする**　可読性を高めるため。不必要な検証コードや過度な柔軟性を避ける。
9. **詳細の記述や分析、動作検証、データの確認をする場合はtmp/配下にノートブックで作成する**　ユーザーが簡単に実行確認できるため。


## Model-Runner-Notebookパターン
過去のテーブルコンペで使用した構成を踏襲し、画像タスクに最適化。詳細なコードはsample_code/自分の過去コンペ/配下を参照。:
- **Model抽象クラス**: `src/model.py` で `train()`, `predict()`, `save_model()`, `load_model()` を定義
- **具体的なモデル**: `src/model_resnet.py`, `src/model_arcface.py` などでModel継承
- **Runnerクラス**: `src/runner.py` でCV管理・学習・予測・評価を一元管理
- **Notebookで実行**: `notebooks/exp_*.ipynb` でパラメータ設定→Runner実行→分析


## 実装の流れ（画像コンペ）
1. **Notebookでパラメータ設定**: `notebooks/exp_*.ipynb` でモデル・CV設定
2. **Runner作成**: モデルクラス・データ・パラメータを渡してRunnerインスタンス化
3. **CV学習**: `runner.train_cv()` で5-fold学習（初回は特徴抽出で時間がかかる）
4. **予測**: `runner.predict_cv()` でアンサンブル予測
5. **閾値チューニング**: `model.predict_with_custom_threshold()` で高速実験
6. **提出**: `runner.save_submission()` でCSV生成

## 主要ディレクトリの役割と追加時の注意点。

```
.
├── README.md                     # リポジトリ全体の簡易概要
├── requirements.txt              # 依存パッケージ
├── configs/
│   └── config.py                 # 設定値（定数/パス）を集中管理
├── data/
│   ├── raw/                      # 生データ（配布物・外部取得データ）
│   │   └── input/                # コンペ配布の入力ファイル類
│   ├── interim/                  # 中間生成物（フィルタ後/正規化後など）
│   ├── features/                 # 特徴量生成結果（数値・埋め込み等）
│   ├── figures/                  # 可視化出力（PNG/HTML等）
│   └── submission/               # 提出用CSVの生成先
├── logs/                         # 実行ログ（日時付きファイル推奨）
├── models/                       # モデル/チェックポイント（必要時のみ）
├── notebooks/                    # 実験/実行用 Notebook（パラメータ調整・可視化・実行）
├── sample_code/                  # 参考サンプル（他人のコードなど）
├── src/                          # ロジックを記載したPython モジュール群
├── tmp/                          # 一時ファイル置き場
└── .github/
	└── copilot-instructions.md   # このリポジトリの開発/運用ガイド
  └── data_discription.md      # データセットの詳細説明
```

追加・変更時の原則:
- 大きい変更を実施する場合は、変更計画を事前に確認する。
- **実験・実行は `notebooks/` で実施**: パラメータ調整、結果確認、可視化はノートブックで行う。
- `src/` に置くコードは「再利用可能な機能」を意識したクラス化・関数化を行う（データ読み込み、特徴抽出、予測ロジックなど）。
- Notebook 内で有効性が確認されたロジックは、再現性確保のため必要に応じて `src/` へ移植。
- 大きい変更を実施する場合は、変更計画を事前に確認する。



# コンペの説明

## コンペ概要

バスケットボール選手判別チャレンジ
このコンペティションのゴールは、バスケットボールの試合動画から切り出された静止画に対し、「特定のバウンディングボックス（bbox）に写っている選手が誰であるか」 を正確に識別することです。

具体的には、画像と 選手の位置（bbox）が与えられるので、その位置にいる選手のID（ラベル） を予測していただきます。

もともとは動画のデータですがみなさんにお渡しするのは動画を静止画として切り出した画像リストです。

各画像にたいして「どこに」「誰が」写っているかの領域(bounding box) x ラベルの情報がメタ情報として渡されます。学習データでは全てのフレームに対してどこに誰がいるかのすべての情報が渡されます。

対してテストデータでは各画像にたいして「どこに」写っているかの bbox 情報のみが渡されますので「誰が」写っているかのラベルを予測してください!


## 注意事項

- 撮影データの学習/テストでのシフト
  - 学習データでは同じシーンを上 (フカン) と横から取った完全な画像が渡されます。
  - 一方ではテストデータでは上・横どちらかだけのパターンがあります。また完全な画像ファイルは渡されず、BBox 内をくり抜いた画像のみが渡されます。

- BBox の精度のシフト
  - 学習データでは、過不足のない完全な BBox が渡されます。
  - 一方で、テストデータの BBox は常に正しいとは限りません。BBox の数が多すぎる / または少なすぎるケースが存在します。さらに、試合途中には選手の入れ替えが発生しています (どのタイミングで入れ替えがあるか?については知らされません)。
  - もしもテストデータで、学習データに存在していない選手 / そもそも選手とみなせない BBox が登場した場合には unknown に該当するラベル -1 を出力してください。
  - 同一フレーム内の BBox にはかさなりがあるケースがあります。重なっている2つの BBox が同一の選手を示す場合には、どちらの BBox にも対象の選手の ID を含めてください。BBox の重なりは IoU により判定されます。正しい bbox との iou が 0.5 を超えた場合にのみ選手のラベル / それ以外では写っていない == -1 となります。(例えば選手の足の一部分だけが写っていても unknown とされるようなケースが存在します)

## 評価指標
Macro F1 で評価を行います。

## 学習用データ

## ./data/raw/input/images

試合動画のフレームごとの画像が格納されています。ファイル名は { クオーター番号 }__{ 画角 }__{ シーンセッション番号 }__{ フレーム番号 }.jpg のルールで命名されています。

- クオーター番号: 試合のクオーターを表す番号。試合の経過に従って番号が増えます。
- 画角: side or top のいずれかの文字列。side の場合横からの, top の場合フカンカメラの画像であることを表します。
- シーンセッション番号: クオーター中のシーンを表す番号。0 から始まり、時間経過に伴って番号が増えます。シーンの前後には一定の時間があいています。
- フレーム番号: 各シーン内での動画フレーム番号: 0 から始まり、時間経過に伴って番号が増えます。各フレーム間の時刻は一定です。

### ./data/raw/input/atmaCup22_2nd_meta/train_meta.csv
各画像のどこに・だれが写っているかを記録しているメタデータです。

- quarter: クオーター番号
- angle: 画角。top or side.
- session: クオーター中のシーンを表すセッション番号。学習データはクオーター中の全画像が含まれているため、セッションは常に 0 です。
- frame: フレーム番号
- x / y / w / h: bbox の位置。pixel として解釈してください。
- label_id: この bbox に写っている選手のID


## テスト用データ

### ./data/raw/input/crops
各フレームに対して BBox 領域が切り抜かれた画像が含まれています。 test_meta.csv の rel_path に対応します。

### ./data/raw/input/atmaCup22_2nd_meta/test_meta.csv
予測対象となる画像と場所が格納されている CSV です。記載の画像の特定の場所にどの選手がいるかを予測してください。

### sample_submission.csv
今回のコンペティションで有効となる sample submission です。label_id 列のみを持つ csv (1列のみなのでカンマでの区切りなし) で test_meta.csv と同じ順序になるようにしてください。

- label_id: test_meta.csv の同一行の bbox に写っている選手のID。もし train_meta.csv にいない選手が写っている場合には -1 を入力してください。





