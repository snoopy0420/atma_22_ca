{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## 1. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from configs.config import *\n",
    "from src.runner import Runner\n",
    "from src.model_resnet_knn import ModelResNet50KNN\n",
    "from src.util import Logger, Util, Metric\n",
    "\n",
    "print(f\"Input dir: {DIR_INPUT}\")\n",
    "print(f\"Model dir: {DIR_MODEL}\")\n",
    "print(f\"Submission dir: {DIR_SUBMISSIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 2. ãƒ­ã‚¬ãƒ¼ã®è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(path=DIR_LOG)\n",
    "\n",
    "def get_run_name(model_type):\n",
    "    \"\"\"runåã®ä½œæˆ\"\"\"\n",
    "    run_name = model_type\n",
    "    suffix = '_' + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "    run_name = run_name + suffix\n",
    "    return run_name\n",
    "\n",
    "logger.info(\"Logger initialized (Local)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 3. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "df_train = pd.read_csv(os.path.join(DIR_INPUT, 'atmaCup22_metadata', 'train_meta.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DIR_INPUT, 'atmaCup22_metadata', 'test_meta.csv'))\n",
    "\n",
    "print(f\"Train: {df_train.shape}\")\n",
    "print(f\"Test: {df_test.shape}\")\n",
    "\n",
    "# âœ… ãƒªãƒ¼ã‚¯ã—ãªã„CVæˆ¦ç•¥: quarter_sessionã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–\n",
    "df_train['group'] = df_train['quarter'] + '_' + df_train['session'].astype(str)\n",
    "\n",
    "print(f\"\\nã€CV Strategyã€‘\")\n",
    "print(f\"  Group column: 'group' (quarter_session)\")\n",
    "print(f\"  Total groups: {df_train['group'].nunique()}\")\n",
    "print(f\"  Avg samples per group: {len(df_train) / df_train['group'].nunique():.1f}\")\n",
    "\n",
    "# ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_train['label_id'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã®å¯è¦–åŒ–\n",
    "label_counts = df_train['label_id'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "label_counts.plot(kind='bar')\n",
    "plt.title('Training Data Label Distribution')\n",
    "plt.xlabel('Label ID')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æœ€é©åŒ–ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¡ãƒ¢\n",
    "memo = \"ResNet50 + KNN method (Local)\"\n",
    "\n",
    "# run_name\n",
    "run_name = get_run_name(model_type=\"resnet50_knn_local\")\n",
    "run_name = \"resnet50_knn_local_202512141406\"\n",
    "\n",
    "print(f\"Run name: {run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆCPU/GPUè‡ªå‹•åˆ¤å®šï¼‰\n",
    "import torch\n",
    "\n",
    "# ãƒ‡ãƒã‚¤ã‚¹ç¢ºèª\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "params = {\n",
    "    'model_name': 'resnet50',\n",
    "    # KNNå›ºæœ‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    'k': 5,\n",
    "    # é–¾å€¤è¨­å®š\n",
    "    'threshold': 0.5,\n",
    "    'min2_threshold': 0.3,\n",
    "    # ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆCPUãªã‚‰å°ã•ã‚ã€GPUãªã‚‰å¤§ãã‚ï¼‰\n",
    "    'batch_size': 64 if device == 'cuda' else 32,\n",
    "    'num_workers': 4 if device == 'cuda' else 2,\n",
    "    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š\n",
    "    'use_cache': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. CVæˆ¦ç•¥è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVè¨­å®š\n",
    "cv_setting = {\n",
    "    'method': 'group',  # 'group' (æ¨å¥¨) or 'stratified_group'\n",
    "    'group_col': 'group',  # ä¸Šã§ä½œæˆã—ãŸquarter_sessionåˆ—\n",
    "    'n_splits': 5,\n",
    "    # æ³¨: GroupKFoldã¯shuffleãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã—ï¼ˆæ™‚ç³»åˆ—é †ã‚’ä¿ã¤ï¼‰\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. Runnerä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnerã®ä½œæˆ\n",
    "runner = Runner(\n",
    "    run_name=run_name,\n",
    "    model_cls=ModelResNet50KNN,\n",
    "    params=params,\n",
    "    df_train=df_train,\n",
    "    df_test=df_test,\n",
    "    cv_setting=cv_setting,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "print(f\"\\nRunner created: {run_name}\")\n",
    "print(f\"Model class: {ModelResNet50KNN.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = runner.build_model(i_fold=0)\n",
    "model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = model._extract_features_batch(df_test, split='test')\n",
    "\n",
    "# é¡ä¼¼åº¦è¨ˆç®—ï¼ˆå­ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰\n",
    "similarities = model._compute_similarities(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(similarities.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import dataset_image\n",
    "import importlib\n",
    "importlib.reload(dataset_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_image import BasketballDataset, get_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# BasketballDatasetã®å‹•ä½œç¢ºèª\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆç”¨ã«å°ã•ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—\n",
    "sample_df = df_train.head(20).copy()\n",
    "\n",
    "# Datasetä½œæˆï¼ˆå­¦ç¿’ç”¨transformï¼‰\n",
    "dataset_train = BasketballDataset(\n",
    "    df=sample_df,\n",
    "    transform=get_transforms(is_train=True),\n",
    "    is_train=True,\n",
    ")\n",
    "\n",
    "# Datasetä½œæˆï¼ˆè©•ä¾¡ç”¨transformï¼‰\n",
    "dataset_val = BasketballDataset(\n",
    "    df=sample_df,\n",
    "    transform=get_transforms(is_train=False),\n",
    "    is_train=False,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Dataset created successfully\")\n",
    "print(f\"  Train dataset size: {len(dataset_train)}\")\n",
    "print(f\"  Val dataset size: {len(dataset_val)}\")\n",
    "\n",
    "# 1ã‚µãƒ³ãƒ—ãƒ«å–å¾—ã—ã¦ç¢ºèª\n",
    "image, label = dataset_train[0]\n",
    "\n",
    "print(f\"\\nâœ… Sample data:\")\n",
    "print(f\"  Image shape: {image.shape}\")\n",
    "print(f\"  Image dtype: {image.dtype}\")\n",
    "print(f\"  Label: {label}\")\n",
    "\n",
    "# ç”»åƒã®å€¤ã®ç¯„å›²ç¢ºèªï¼ˆæ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ï¼‰\n",
    "print(f\"\\nâœ… Image statistics:\")\n",
    "\n",
    "print(f\"  Min: {image.min():.3f}\")\n",
    "print(f\"  Max: {image.max():.3f}\")\n",
    "print(f\"  Mean: {image.mean():.3f}\")\n",
    "print(f\"  Std: {image.std():.3f}\")\n",
    "\n",
    "# DataLoaderã§ãƒãƒƒãƒå‡¦ç†ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ç¢ºèª\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=0  # ç¢ºèªç”¨ã«0ã«è¨­å®š\n",
    ")\n",
    "\n",
    "batch_images, batch_labels = next(iter(dataloader))\n",
    "\n",
    "print(f\"\\nâœ… DataLoader batch:\")\n",
    "print(f\"  Batch images shape: {batch_images.shape}\")\n",
    "print(f\"  Batch labels shape: {batch_labels.shape}\")\n",
    "\n",
    "print(f\"\\nâœ… All checks passed! BasketballDataset is working correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 7. 5-Fold CVå­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 5-fold CVå­¦ç¿’\n",
    "# âš ï¸ åˆå›å®Ÿè¡Œæ™‚ã¯ç‰¹å¾´æŠ½å‡ºã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆCPU: 1-2æ™‚é–“, GPU: 20-30åˆ†ï¼‰\n",
    "# 2å›ç›®ä»¥é™ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚é«˜é€Ÿã§ã™ï¼ˆæ•°åˆ†ï¼‰\n",
    "\n",
    "scores = runner.train_cv()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"CV Score (Macro F1): {np.mean(scores):.5f} Â± {np.std(scores):.5f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. è©•ä¾¡ï¼ˆOOFï¼‰\n",
    "fold_scores, oof_score = runner.metric_cv()\n",
    "\n",
    "print(f\"OOF Score: {oof_score:.5f}\")\n",
    "print(f\"Fold Scores: {fold_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 8. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# CVå…¨ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬\n",
    "pred_test = runner.predict_cv()\n",
    "\n",
    "print(f\"\\nTest predictions shape: {pred_test.shape}\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(pred_test['label_id'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# äºˆæ¸¬åˆ†å¸ƒã®å¯è¦–åŒ–\n",
    "plt.figure(figsize=(10, 5))\n",
    "pred_test['label_id'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Test Prediction Distribution (KNN - Local)')\n",
    "plt.xlabel('Label ID')\n",
    "plt.ylabel('Count')\n",
    "plt.axhline(y=len(pred_test)/11, color='r', linestyle='--', alpha=0.5, label='Uniform')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## 9. æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n",
    "submission_path = runner.save_submission(pred_test, run_name)\n",
    "\n",
    "print(f\"\\nâœ… Submission file saved: {submission_path}\")\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(pred_test.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## 10. kã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kã®å€¤ã‚’å¤‰ãˆã¦äºˆæ¸¬ï¼ˆé¡ä¼¼åº¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†åˆ©ç”¨ã§é«˜é€Ÿï¼‰\n",
    "k_values = [3, 5, 7, 10, 15]\n",
    "k_results = []\n",
    "\n",
    "print(\"\\n=== Testing different k values ===\")\n",
    "print(\"(Using cached similarities for fast tuning)\\n\")\n",
    "\n",
    "for k in k_values:\n",
    "    predictions_list = []\n",
    "    \n",
    "    for i_fold in range(runner.n_splits):\n",
    "        model = runner.load_model_cv(i_fold)\n",
    "        \n",
    "        if hasattr(model, 'test_similarities') and model.test_similarities is not None:\n",
    "            pred = model.predict_with_custom_threshold(\n",
    "                threshold=params['threshold'],\n",
    "                min2_threshold=params['min2_threshold'],\n",
    "                k=k\n",
    "            )\n",
    "            predictions_list.append(pred)\n",
    "    \n",
    "    if predictions_list:\n",
    "        predictions_array = np.array(predictions_list)\n",
    "        final_pred = []\n",
    "        for i in range(predictions_array.shape[1]):\n",
    "            values, counts = np.unique(predictions_array[:, i], return_counts=True)\n",
    "            final_pred.append(values[np.argmax(counts)])\n",
    "        \n",
    "        unknown_count = np.sum(np.array(final_pred) == -1)\n",
    "        unknown_ratio = unknown_count / len(final_pred) * 100\n",
    "        \n",
    "        k_results.append({\n",
    "            'k': k,\n",
    "            'unknown_count': unknown_count,\n",
    "            'unknown_ratio': unknown_ratio\n",
    "        })\n",
    "        \n",
    "        print(f\"k={k:2d}: unknown={unknown_count:4d} ({unknown_ratio:5.2f}%)\")\n",
    "\n",
    "df_k_results = pd.DataFrame(k_results)\n",
    "print(\"\\n=== k-value tuning results ===\")\n",
    "print(df_k_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kã¨unknownæ¯”ç‡ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–\n",
    "if len(k_results) > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df_k_results['k'], df_k_results['unknown_ratio'], marker='o', linewidth=2)\n",
    "    plt.xlabel('k (Number of neighbors)', fontsize=12)\n",
    "    plt.ylabel('Unknown Ratio (%)', fontsize=12)\n",
    "    plt.title('KNN: Effect of k on Unknown Predictions (Local)', fontsize=14)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## 11. é–¾å€¤ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é–¾å€¤ã‚’å¤‰ãˆã¦äºˆæ¸¬\n",
    "threshold_values = np.arange(0.3, 0.8, 0.05)\n",
    "threshold_results = []\n",
    "\n",
    "print(\"\\n=== Testing different threshold values ===\")\n",
    "print(f\"(Using k={params['k']}, min2_threshold={params['min2_threshold']})\\n\")\n",
    "\n",
    "for threshold in threshold_values:\n",
    "    predictions_list = []\n",
    "    \n",
    "    for i_fold in range(runner.n_splits):\n",
    "        model = runner.load_model_cv(i_fold)\n",
    "        \n",
    "        if hasattr(model, 'test_similarities') and model.test_similarities is not None:\n",
    "            pred = model.predict_with_custom_threshold(\n",
    "                threshold=threshold,\n",
    "                min2_threshold=params['min2_threshold'],\n",
    "                k=params['k']\n",
    "            )\n",
    "            predictions_list.append(pred)\n",
    "    \n",
    "    if predictions_list:\n",
    "        predictions_array = np.array(predictions_list)\n",
    "        final_pred = []\n",
    "        for i in range(predictions_array.shape[1]):\n",
    "            values, counts = np.unique(predictions_array[:, i], return_counts=True)\n",
    "            final_pred.append(values[np.argmax(counts)])\n",
    "        \n",
    "        unknown_count = np.sum(np.array(final_pred) == -1)\n",
    "        unknown_ratio = unknown_count / len(final_pred) * 100\n",
    "        \n",
    "        threshold_results.append({\n",
    "            'threshold': threshold,\n",
    "            'unknown_count': unknown_count,\n",
    "            'unknown_ratio': unknown_ratio\n",
    "        })\n",
    "        \n",
    "        print(f\"threshold={threshold:.2f}: unknown={unknown_count:4d} ({unknown_ratio:5.2f}%)\")\n",
    "\n",
    "df_threshold_results = pd.DataFrame(threshold_results)\n",
    "print(\"\\n=== Threshold tuning results ===\")\n",
    "print(df_threshold_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é–¾å€¤ã¨unknownæ¯”ç‡ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–\n",
    "if len(threshold_results) > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df_threshold_results['threshold'], df_threshold_results['unknown_ratio'], \n",
    "             marker='o', linewidth=2, color='orange')\n",
    "    plt.xlabel('Threshold', fontsize=12)\n",
    "    plt.ylabel('Unknown Ratio (%)', fontsize=12)\n",
    "    plt.title('KNN: Effect of Threshold on Unknown Predictions (Local)', fontsize=14)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## 12. ã¾ã¨ã‚\n",
    "\n",
    "### âœ… å®Ÿè¡Œå®Œäº†å†…å®¹\n",
    "1. KNNæ³•ã§ã®5-fold CVå­¦ç¿’ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒï¼‰\n",
    "2. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬\n",
    "3. kã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“ï¼ˆk=3,5,7,10,15ï¼‰\n",
    "4. é–¾å€¤ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“ï¼ˆthreshold=0.3~0.8ï¼‰\n",
    "5. æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
    "\n",
    "### ğŸ“Š KNNæ³•ã®ç‰¹å¾´\n",
    "- âœ… è¨“ç·´ãƒ‡ãƒ¼ã‚¿å…¨ä½“ï¼ˆ24,920ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã‚’æ´»ç”¨\n",
    "- âœ… kã§æŸ”è»Ÿã«èª¿æ•´å¯èƒ½\n",
    "- âš ï¸ Prototypeæ³•ã‚ˆã‚Šæ¨è«–ãŒé…ã„\n",
    "- âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã„\n",
    "\n",
    "### ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "- [ ] Prototypeæ³•ã¨ç²¾åº¦æ¯”è¼ƒ\n",
    "- [ ] EfficientNet-B0ã§å®Ÿé¨“\n",
    "- [ ] Prototype + KNNã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "- [ ] ArcFaceå°å…¥æ¤œè¨\n",
    "\n",
    "### ğŸ’¾ çµæœã®ä¿å­˜å ´æ‰€\n",
    "- ãƒ¢ãƒ‡ãƒ«: `models/`\n",
    "- ãƒ­ã‚°: `logs/`\n",
    "- æå‡ºãƒ•ã‚¡ã‚¤ãƒ«: `data/submission/`\n",
    "- ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥: `data/features/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atma_22_ca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
