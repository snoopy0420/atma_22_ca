{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from configs.config import *\n",
    "\n",
    "print(\"=== Environment Check ===\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"\\nProject root: {Path.cwd().parent}\")\n",
    "print(f\"Data dir: {DIR_INPUT}\")\n",
    "print(f\"\\nData exists: {os.path.exists(DIR_INPUT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n",
    "train_meta_path = os.path.join(DIR_INPUT, 'atmaCup22_metadata', 'train_meta.csv')\n",
    "test_meta_path = os.path.join(DIR_INPUT, 'atmaCup22_metadata', 'test_meta.csv')\n",
    "images_dir = os.path.join(DIR_INPUT, 'images')\n",
    "\n",
    "print(\"=== Data Files Check ===\")\n",
    "print(f\"âœ… train_meta.csv: {os.path.exists(train_meta_path)}\")\n",
    "print(f\"âœ… test_meta.csv: {os.path.exists(test_meta_path)}\")\n",
    "print(f\"âœ… images/: {os.path.exists(images_dir)}\")\n",
    "\n",
    "if os.path.exists(images_dir):\n",
    "    image_files = list(Path(images_dir).glob('*.jpg'))\n",
    "    print(f\"\\nTotal images: {len(image_files)}\")\n",
    "    if len(image_files) > 0:\n",
    "        print(f\"Sample: {image_files[0].name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. rclone ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "\n",
    "### 2.1 rcloneã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcloneãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "!rclone version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### ğŸ“ rcloneã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•\n",
    "\n",
    "rcloneãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã€ä»¥ä¸‹ã®æ‰‹é †ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š\n",
    "\n",
    "#### Windows\n",
    "```powershell\n",
    "# Chocolateyã‚’ä½¿ã†å ´åˆ\n",
    "choco install rclone\n",
    "\n",
    "# ã¾ãŸã¯å…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "# https://rclone.org/downloads/\n",
    "```\n",
    "\n",
    "#### macOS\n",
    "```bash\n",
    "brew install rclone\n",
    "```\n",
    "\n",
    "#### Linux\n",
    "```bash\n",
    "curl https://rclone.org/install.sh | sudo bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 2.2 Google Driveè¨­å®š\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§rcloneè¨­å®šã‚’é–‹å§‹ã—ã¾ã™ï¼ˆåˆå›ã®ã¿ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcloneè¨­å®šï¼ˆã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œæ¨å¥¨ï¼‰\n",
    "# ã“ã®ã‚»ãƒ«ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ãŸã¾ã¾ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
    "\n",
    "# !rclone config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### ğŸ“ rcloneè¨­å®šæ‰‹é †ï¼ˆåˆå›ã®ã¿ï¼‰\n",
    "\n",
    "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ `rclone config` ã‚’å®Ÿè¡Œã—ã€ä»¥ä¸‹ã®æ‰‹é †ã§è¨­å®šï¼š\n",
    "\n",
    "1. `n` (New remote) ã‚’é¸æŠ\n",
    "2. name: `gdrive` ã¨å…¥åŠ›ï¼ˆæ¨å¥¨åï¼‰\n",
    "3. Storage: `drive` (Google Drive) ã‚’é¸æŠ\n",
    "4. client_id: ç©ºç™½ã®ã¾ã¾Enter\n",
    "5. client_secret: ç©ºç™½ã®ã¾ã¾Enter\n",
    "6. scope: `1` (Full access) ã‚’é¸æŠ\n",
    "7. root_folder_id: ç©ºç™½ã®ã¾ã¾Enter\n",
    "8. service_account_file: ç©ºç™½ã®ã¾ã¾Enter\n",
    "9. Edit advanced config?: `n`\n",
    "10. Use auto config?: `y`\n",
    "11. ãƒ–ãƒ©ã‚¦ã‚¶ã§èªè¨¼\n",
    "12. Configure as team drive?: `n`\n",
    "13. `y` (Yes this is OK) ã§å®Œäº†\n",
    "14. `q` (Quit config) ã§çµ‚äº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcloneè¨­å®šã®ç¢ºèª\n",
    "!rclone listremotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "âœ… `gdrive:` ãŒè¡¨ç¤ºã•ã‚Œã‚Œã°OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 3. ãƒ‡ãƒ¼ã‚¿ã‚’Google Driveã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "### 3.1 ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ç¢ºèª\n",
    "# ã¾ãšãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "!rclone lsd gdrive:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### 3.2 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆåˆå›ã®ã¿ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveä¸Šã«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ\n",
    "PROJECT_FOLDER = \"atma22\"  # â˜…å¥½ããªåå‰ã«å¤‰æ›´å¯èƒ½â˜…\n",
    "\n",
    "# ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆï¼ˆæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ï¼‰\n",
    "!rclone mkdir gdrive:{PROJECT_FOLDER}\n",
    "!rclone mkdir gdrive:{PROJECT_FOLDER}/data\n",
    "!rclone mkdir gdrive:{PROJECT_FOLDER}/models\n",
    "!rclone mkdir gdrive:{PROJECT_FOLDER}/logs\n",
    "\n",
    "print(f\"\\nâœ… Created folder structure in gdrive:{PROJECT_FOLDER}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ç¢ºèª\n",
    "!rclone lsd gdrive:{PROJECT_FOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### 3.3 ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿ã€æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰\n",
    "\n",
    "âš ï¸ **æ³¨æ„**: ç”»åƒãƒ‡ãƒ¼ã‚¿ã¯æ•°GBã‚ã‚‹ãŸã‚ã€åˆå›ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«30åˆ†ã€œ1æ™‚é–“ã‹ã‹ã‚Šã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºç¢ºèªï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‰ï¼‰\n",
    "import shutil\n",
    "\n",
    "data_size_gb = shutil.disk_usage(DIR_INPUT).used / (1024**3)\n",
    "print(f\"Data directory size: {data_size_gb:.2f} GB\")\n",
    "print(f\"\\nâš ï¸ Upload time estimate: {data_size_gb * 2:.0f}-{data_size_gb * 4:.0f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿ï¼‰\n",
    "# syncã‚³ãƒãƒ³ãƒ‰: ãƒ­ãƒ¼ã‚«ãƒ«ã¨ãƒªãƒ¢ãƒ¼ãƒˆã‚’åŒæœŸï¼ˆå·®åˆ†ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰\n",
    "\n",
    "print(\"=== Uploading data to Google Drive ===\")\n",
    "print(f\"Source: {DIR_INPUT}\")\n",
    "print(f\"Destination: gdrive:{PROJECT_FOLDER}/data/raw/input/\")\n",
    "print(\"\\nâ³ Starting upload... (this may take 30-60 minutes)\\n\")\n",
    "\n",
    "!rclone sync {DIR_INPUT} gdrive:{PROJECT_FOLDER}/data/raw/input/ --progress --transfers 4 --checkers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç¢ºèª\n",
    "print(\"=== Verifying upload ===\")\n",
    "!rclone ls gdrive:{PROJECT_FOLDER}/data/raw/input/atmaCup22_metadata/\n",
    "print(\"\\n\")\n",
    "!rclone size gdrive:{PROJECT_FOLDER}/data/raw/input/images/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 3.4 sample_submission.csvã‚‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submissionç¢ºèª\n",
    "sample_submission_path = os.path.join(DIR_INPUT, 'atmaCup22_metadata', 'sample_submission.csv')\n",
    "\n",
    "if os.path.exists(sample_submission_path):\n",
    "    print(f\"âœ… sample_submission.csv exists\")\n",
    "    \n",
    "    # å†…å®¹ç¢ºèª\n",
    "    df_sample = pd.read_csv(sample_submission_path)\n",
    "    print(f\"\\nShape: {df_sample.shape}\")\n",
    "    print(df_sample.head())\n",
    "else:\n",
    "    print(\"âš ï¸ sample_submission.csv not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 4. Gitãƒªãƒã‚¸ãƒˆãƒªæº–å‚™\n",
    "\n",
    "### 4.1 .gitignoreç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .gitignoreç¢ºèª\n",
    "gitignore_path = Path.cwd().parent / '.gitignore'\n",
    "\n",
    "if gitignore_path.exists():\n",
    "    print(\"âœ… .gitignore exists\")\n",
    "    print(\"\\nContents:\")\n",
    "    with open(gitignore_path, 'r', encoding='utf-8') as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"âš ï¸ .gitignore not found\")\n",
    "    print(\"\\nRecommended .gitignore:\")\n",
    "    print(\"\"\"\n",
    "# Data\n",
    "data/\n",
    "!data/.gitkeep\n",
    "\n",
    "# Models\n",
    "models/\n",
    "!models/.gitkeep\n",
    "\n",
    "# Logs\n",
    "logs/\n",
    "!logs/.gitkeep\n",
    "\n",
    "# Python\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    ".Python\n",
    "\n",
    "# Jupyter\n",
    ".ipynb_checkpoints/\n",
    "\n",
    "# IDE\n",
    ".vscode/\n",
    ".idea/\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### 4.2 GitåˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitçŠ¶æ…‹ç¢ºèª\n",
    "%cd ..\n",
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### ğŸ“ GitåˆæœŸåŒ–æ‰‹é †ï¼ˆåˆå›ã®ã¿ï¼‰\n",
    "\n",
    "Gitãƒªãƒã‚¸ãƒˆãƒªãŒæœªåˆæœŸåŒ–ã®å ´åˆã€ä»¥ä¸‹ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œï¼š\n",
    "\n",
    "```bash\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã§\n",
    "git init\n",
    "git add src/ configs/ notebooks/ requirements.txt README.md\n",
    "git commit -m \"Initial commit\"\n",
    "\n",
    "# GitHubãƒªãƒã‚¸ãƒˆãƒªä½œæˆå¾Œ\n",
    "git remote add origin https://github.com/YOUR_USERNAME/atma_22_ca.git\n",
    "git branch -M main\n",
    "git push -u origin main\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’ã‚³ãƒŸãƒƒãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ã¯é™¤å¤–ï¼‰\n",
    "# ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œæ¨å¥¨\n",
    "\n",
    "# !git add src/ configs/ notebooks/ requirements.txt\n",
    "# !git commit -m \"Prepare for Colab training\"\n",
    "# !git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 5. ãƒ­ãƒ¼ã‚«ãƒ«ã§å°è¦æ¨¡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n",
    "\n",
    "Colabã§å®Ÿè¡Œã™ã‚‹å‰ã«ã€ãƒ­ãƒ¼ã‚«ãƒ«ã§å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆã‚µãƒ³ãƒ—ãƒ«ã®ã¿ï¼‰\n",
    "import sys\n",
    "sys.path.append('..')  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ\n",
    "\n",
    "from src.util import Logger\n",
    "from src.model_resnet_knn import ModelResNet50KNN\n",
    "from configs.config import *\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(DIR_INPUT, 'atmaCup22_metadata', 'train_meta.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DIR_INPUT, 'atmaCup22_metadata', 'test_meta.csv'))\n",
    "\n",
    "# å°è¦æ¨¡ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ100ä»¶ã®ã¿ï¼‰\n",
    "df_train_sample = df_train.head(100).copy()\n",
    "df_test_sample = df_test.head(20).copy()\n",
    "\n",
    "print(f\"Train sample: {df_train_sample.shape}\")\n",
    "print(f\"Test sample: {df_test_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆå°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼‰\n",
    "logger = Logger(path=DIR_LOG)\n",
    "\n",
    "params = {\n",
    "    'model_name': 'resnet50',\n",
    "    'k': 3,\n",
    "    'threshold': 0.5,\n",
    "    'min2_threshold': 0.3,\n",
    "    'batch_size': 16,  # å°ã•ã‚\n",
    "    'num_workers': 0,  # ãƒ†ã‚¹ãƒˆãªã®ã§0\n",
    "    'use_cache': True,\n",
    "}\n",
    "\n",
    "print(\"=== Creating model for test ===\")\n",
    "model = ModelResNet50KNN(\n",
    "    run_fold_name='test_local',\n",
    "    params=params,\n",
    "    out_dir_name='../models',\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "print(\"\\n=== Training on small sample ===\")\n",
    "model.train(df_train_sample)\n",
    "\n",
    "print(\"\\n=== Predicting on small sample ===\")\n",
    "pred = model.predict(df_test_sample)\n",
    "\n",
    "print(f\"\\nâœ… Test completed!\")\n",
    "print(f\"Predictions: {pred['label_id'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## 6. Colabå®Ÿè¡Œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n",
    "\n",
    "ä»¥ä¸‹ã‚’ã™ã¹ã¦ç¢ºèªã—ã¦ã‹ã‚‰Colabã§å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "checklist = []\n",
    "\n",
    "# 1. rcloneè¨­å®š\n",
    "try:\n",
    "    result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "    has_gdrive = 'gdrive:' in result.stdout\n",
    "    checklist.append((\"âœ…\" if has_gdrive else \"âŒ\", \"rcloneè¨­å®šå®Œäº†ï¼ˆgdrive:ï¼‰\", has_gdrive))\n",
    "except:\n",
    "    checklist.append((\"âŒ\", \"rcloneè¨­å®šå®Œäº†ï¼ˆgdrive:ï¼‰\", False))\n",
    "\n",
    "# 2. ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "try:\n",
    "    result = subprocess.run(['rclone', 'ls', f'gdrive:{PROJECT_FOLDER}/data/raw/input/atmaCup22_metadata/'], \n",
    "                          capture_output=True, text=True, timeout=10)\n",
    "    has_data = 'train_meta.csv' in result.stdout\n",
    "    checklist.append((\"âœ…\" if has_data else \"âŒ\", f\"ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼ˆgdrive:{PROJECT_FOLDER}/data/ï¼‰\", has_data))\n",
    "except:\n",
    "    checklist.append((\"âŒ\", f\"ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼ˆgdrive:{PROJECT_FOLDER}/data/ï¼‰\", False))\n",
    "\n",
    "# 3. Git push\n",
    "try:\n",
    "    result = subprocess.run(['git', 'remote', '-v'], capture_output=True, text=True, cwd='..')\n",
    "    has_remote = 'origin' in result.stdout\n",
    "    checklist.append((\"âœ…\" if has_remote else \"âŒ\", \"GitHubãƒªãƒã‚¸ãƒˆãƒªè¨­å®šå®Œäº†\", has_remote))\n",
    "except:\n",
    "    checklist.append((\"âŒ\", \"GitHubãƒªãƒã‚¸ãƒˆãƒªè¨­å®šå®Œäº†\", False))\n",
    "\n",
    "# 4. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ\n",
    "test_model_exists = os.path.exists('../models/test_local')\n",
    "checklist.append((\"âœ…\" if test_model_exists else \"âš ï¸\", \"ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå®Œäº†\", test_model_exists))\n",
    "\n",
    "# 5. .gitignore\n",
    "gitignore_exists = os.path.exists('../.gitignore')\n",
    "checklist.append((\"âœ…\" if gitignore_exists else \"âš ï¸\", \".gitignoreè¨­å®š\", gitignore_exists))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ã€Colabå®Ÿè¡Œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã€‘\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for icon, item, status in checklist:\n",
    "    print(f\"{icon} {item}\")\n",
    "\n",
    "all_ok = all([status for _, _, status in checklist[:3]])  # æœ€åˆã®3ã¤ã¯å¿…é ˆ\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_ok:\n",
    "    print(\"ğŸ‰ æº–å‚™å®Œäº†ï¼Google Colabã§å®Ÿè¡Œã§ãã¾ã™\")\n",
    "    print(\"\\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "    print(\"1. notebooks/exp_knn_colab.ipynb ã‚’Google Colabã§é–‹ã\")\n",
    "    print(\"2. GITHUB_REPO, GDRIVE_DATA_PATH, GDRIVE_BACKUP_PATH ã‚’è¨­å®š\")\n",
    "    print(f\"   - GDRIVE_DATA_PATH = \\\"gdrive:{PROJECT_FOLDER}/data\\\"\")\n",
    "    print(f\"   - GDRIVE_BACKUP_PATH = \\\"gdrive:{PROJECT_FOLDER}\\\"\")\n",
    "    print(\"3. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¿ã‚¤ãƒ—ã‚’GPUã«å¤‰æ›´\")\n",
    "    print(\"4. ã‚»ã‚¯ã‚·ãƒ§ãƒ³1ã‹ã‚‰é †ã«å®Ÿè¡Œ\")\n",
    "else:\n",
    "    print(\"âš ï¸ ã¾ã æº–å‚™ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“\")\n",
    "    print(\"\\nâŒãƒãƒ¼ã‚¯ã®é …ç›®ã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## 7. Colabå®Ÿè¡Œæ™‚ã®è¨­å®šå€¤ãƒ¡ãƒ¢\n",
    "\n",
    "Colabã§å®Ÿè¡Œã™ã‚‹éš›ã«å¿…è¦ãªè¨­å®šå€¤ã‚’è¨˜éŒ²ã—ã¦ãŠãã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHubãƒªãƒã‚¸ãƒˆãƒªURLå–å¾—\n",
    "try:\n",
    "    result = subprocess.run(['git', 'remote', 'get-url', 'origin'], \n",
    "                          capture_output=True, text=True, cwd='..')\n",
    "    github_url = result.stdout.strip()\n",
    "except:\n",
    "    github_url = \"ï¼ˆæœªè¨­å®šï¼‰\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ã€Colabå®Ÿè¡Œæ™‚ã®è¨­å®šå€¤ã€‘\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nexp_knn_colab.ipynb ã®ä»¥ä¸‹ã®å¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„:\\n\")\n",
    "print(f'GITHUB_REPO = \"{github_url}\"')\n",
    "print(f'GDRIVE_DATA_PATH = \"gdrive:{PROJECT_FOLDER}/data\"')\n",
    "print(f'GDRIVE_BACKUP_PATH = \"gdrive:{PROJECT_FOLDER}\"')\n",
    "print(\"\\nPROJECT_NAME = \\\"atma_22_ca\\\"\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼ç”¨\n",
    "print(\"\\nğŸ“‹ ä»¥ä¸‹ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦Colabã«è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„:\\n\")\n",
    "print(f\"\"\"GITHUB_REPO = \"{github_url}\"\n",
    "GDRIVE_DATA_PATH = \"gdrive:{PROJECT_FOLDER}/data\"\n",
    "GDRIVE_BACKUP_PATH = \"gdrive:{PROJECT_FOLDER}\"\n",
    "PROJECT_NAME = \"atma_22_ca\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## ã¾ã¨ã‚\n",
    "\n",
    "### âœ… å®Œäº†ã—ãŸä½œæ¥­\n",
    "1. rcloneè¨­å®šï¼ˆGoogle Driveæ¥ç¶šï¼‰\n",
    "2. ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ­ãƒ¼ã‚«ãƒ« â†’ Google Driveï¼‰\n",
    "3. Gitãƒªãƒã‚¸ãƒˆãƒªæº–å‚™\n",
    "4. ãƒ­ãƒ¼ã‚«ãƒ«å‹•ä½œç¢ºèª\n",
    "5. Colabå®Ÿè¡Œæº–å‚™å®Œäº†ãƒã‚§ãƒƒã‚¯\n",
    "\n",
    "### ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "1. Google Colabã§ `notebooks/exp_knn_colab.ipynb` ã‚’é–‹ã\n",
    "2. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¿ã‚¤ãƒ—ã‚’GPUã«å¤‰æ›´\n",
    "3. ä¸Šè¨˜ã®è¨­å®šå€¤ã‚’å…¥åŠ›\n",
    "4. ã‚»ã‚¯ã‚·ãƒ§ãƒ³1ã‹ã‚‰é †ã«å®Ÿè¡Œ\n",
    "\n",
    "### ğŸ’¡ Tips\n",
    "- **åˆå›ã®ã¿æ™‚é–“ãŒã‹ã‹ã‚‹**: ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ30-60åˆ†ï¼‰\n",
    "- **2å›ç›®ä»¥é™ã¯é«˜é€Ÿ**: rcloneãŒå·®åˆ†ã®ã¿åŒæœŸ\n",
    "- **Colabå®Ÿè¡Œå¾Œ**: çµæœãŒGoogle Driveã«è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã•ã‚Œã‚‹\n",
    "- **ãƒ­ãƒ¼ã‚«ãƒ«åŒæœŸ**: `rclone sync gdrive:{PROJECT_FOLDER}/models ./models` ã§å–å¾—"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
